# -*- mode: ruby -*-
# vi: set ft=ruby :
#
# Change the following for your network setup:
#   MASTER_NODE_IP
#   eth1 IP addresses
#   bridged network config
#   Replace instances of 172.16.200.x to your local network
#   DOCKER_VERSION
#   KUBE_VERSION

# Documentation for HA Master setup using Kubeadm
# https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/

servers = [
    {
        :name => "k8s-lb01",
        :type => "loadbalancer",
        :box => "ubuntu/bionic64",
        :box_version => "20200124.0.0",
        :eth1 => "172.16.200.60",
        :mem => "1024",
        :cpu => "1"
    },
    {
        :name => "k8s-master01",
        :type => "master",
        :box => "ubuntu/bionic64",
        :box_version => "20200124.0.0",
        :eth1 => "172.16.200.55",
        :mem => "3072",
        :cpu => "3"
    },
    {
        :name => "k8s-master02",
        :type => "smaster",
        :box => "ubuntu/bionic64",
        :box_version => "20200124.0.0",
        :eth1 => "172.16.200.56",
        :mem => "3072",
        :cpu => "3"
    },
    {
        :name => "k8s-master03",
        :type => "smaster",
        :box => "ubuntu/bionic64",
        :box_version => "20200124.0.0",
        :eth1 => "172.16.200.57",
        :mem => "3072",
        :cpu => "3"
    }
]

# This script will install Docker
$installDocker = <<-SCRIPT
    # install docker v18.09 - https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-docker-engine---community-1
    # list available versions - apt-cache madison docker-ce
    DOCKER_VERSION=5:19.03.4~3-0~ubuntu-$(lsb_release -cs)

    sudo apt-get upgrade -y

    # Install Docker CE
    ## Set up the repository:
    ### Install packages to allow apt to use a repository over HTTPS
    sudo apt-get update && sudo apt-get install -y \
    apt-transport-https ca-certificates curl software-properties-common

    ### Add Dockerâ€™s official GPG key
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

    ### Add Docker apt repository.
    sudo add-apt-repository \
    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
    $(lsb_release -cs) \
    stable"

    ## Install Docker CE.
    sudo apt-get update && sudo apt-get install -y \
      containerd.io=1.2.10-3 \
      docker-ce=$DOCKER_VERSION \
      docker-ce-cli=$DOCKER_VERSION
    
    # exclude Docker from getting updated so it won't break compatibility
    sudo apt-mark hold docker-ce docker-ce-cli containerd.io

    # run docker commands as vagrant user
    usermod -aG docker vagrant

    # Setup cgroupdriver as systemd - https://kubernetes.io/docs/setup/cri/
    cat > /etc/docker/daemon.json <<EOF
{
    "exec-opts": ["native.cgroupdriver=systemd"],
    "log-driver": "json-file",
    "log-opts": {
      "max-size": "100m"
    },
    "storage-driver": "overlay2"
}
EOF

    # Setup Docker service
    mkdir -p /etc/systemd/system/docker.service.d
    systemctl daemon-reload
    systemctl restart docker
    systemctl enable docker.service
    systemctl start docker.service

    # kubelet requires swap off
    swapoff -a

    # keep swap off after reboot
    sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

    # add hostname to /etc/hosts file
    ETC_HOSTS=/etc/hosts
    IP_ADDR=`ip route get 1 | awk '{print $7;exit}'`
    HOST_NAME=$(hostname)
    HOSTS_LINE="$IP_ADDR\t$HOST_NAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"
SCRIPT

# This script to install k8s using kubeadm will get executed after a box is provisioned
$installKubeComponents = <<-SCRIPT
    KUBE_VERSION=1.17.2-00
    # install kubeadm - https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
    curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
    echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list
    
    sudo apt-get update
    sudo apt-get install -y kubelet=$KUBE_VERSION kubeadm=$KUBE_VERSION kubectl=$KUBE_VERSION

    # exclude Kube components from getting updated during normal maintenance
    sudo apt-mark hold kubelet kubeadm kubectl

    # kubelet requires swap off
    swapoff -a

    # keep swap off after reboot
    sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

    # add hostname to /etc/hosts file
    ETC_HOSTS=/etc/hosts
    IP_ADDR=`ip route get 1 | awk '{print $7;exit}'`
    HOST_NAME=$(hostname)
    HOSTS_LINE="$IP_ADDR\t$HOST_NAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"
SCRIPT

$configureMaster = <<-SCRIPT
    echo "This is a master node"
    # ip of this box
    IP_ADDR=`ip route get 1 | awk '{print $7;exit}'`
    POD_CIDR="172.20.0.0/16"
    CALICO_VERSION=v3.10

    # setup load balancer's hostname in hosts file
    ETC_HOSTS=/etc/hosts
    LB_HOSTNAME="k8s-lb01"
    HOSTS_LINE="172.16.200.60\t$LB_HOSTNAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"

    # firewall config to allow necessary master node ports - allowing kube subnet
    # sudo ufw allow 22/tcp
    # sudo ufw allow 6443/tcp
    # sudo ufw allow 2379:2380/tcp
    # sudo ufw allow 10250:10252/tcp
    sudo ufw allow from 172.16.200.0/24

    # install k8s master
    HOST_NAME=$(hostname)
    #kubeadm init --apiserver-advertise-address=$IP_ADDR --apiserver-cert-extra-sans=$IP_ADDR,$HOST_NAME \
    #--node-name $HOST_NAME --pod-network-cidr=$POD_CIDR --control-plane-endpoint $HOST_NAME:6443
    
    # install k8s master with load balancer
    # generate cert key to pass to join script later
    # https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-alpha/#cmd-certs-certificate-key
    CERT_KEY=$(kubeadm alpha certs certificate-key)
    sudo kubeadm init --control-plane-endpoint "$LB_HOSTNAME:6443" --upload-certs \
    --pod-network-cidr=$POD_CIDR --certificate-key $CERT_KEY

    # copying credentials to regular user - vagrant
    sudo --user=vagrant mkdir -p /home/vagrant/.kube
    cp -i /etc/kubernetes/admin.conf /home/vagrant/.kube/config
    chown $(id -u vagrant):$(id -g vagrant) /home/vagrant/.kube/config

    # install Calico pod network addon
    export KUBECONFIG=/etc/kubernetes/admin.conf
    curl https://docs.projectcalico.org/$CALICO_VERSION/manifests/calico.yaml -O
    sed -i -e "s?192.168.0.0/16?$POD_CIDR?g" calico.yaml
    kubectl apply -f calico.yaml

    # Create join shell script for worker nodes with v=2 for more verbosity to help with troubleshooting
    kubeadm token create --print-join-command >> /etc/kubeadm_join_cmd.sh
    sudo sed -i '$ s/$/ --v=2/' /etc/kubeadm_join_cmd.sh
    chmod +x /etc/kubeadm_join_cmd.sh

    # Create join shell script for master nodes with v=2 for more verbosity to help with troubleshooting
    # https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/#cmd-token-create
    kubeadm token create --print-join-command --certificate-key $CERT_KEY >> /etc/kubeadm_master_join_cmd.sh
    sudo sed -i '$ s/$/ --v=2/' /etc/kubeadm_master_join_cmd.sh
    chmod +x /etc/kubeadm_master_join_cmd.sh

    # required for setting up password less ssh between guest VMs
    sudo sed -i "/^[^#]*PasswordAuthentication[[:space:]]no/c\PasswordAuthentication yes" /etc/ssh/sshd_config
    sudo service sshd restart

SCRIPT

$configureSecondaryMasters = <<-SCRIPT
    echo "This is a secondary master node"
    # Add master node to /etc/hosts file
    ETC_HOSTS=/etc/hosts
    MASTER_NODE_IP="172.16.200.55"
    MASTER_HOST_NAME="k8s-master01"
    HOSTS_LINE="$MASTER_NODE_IP\t$MASTER_HOST_NAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"

    # setup load balancer's hostname in hosts file
    LB_HOSTNAME="k8s-lb01"
    HOSTS_LINE="172.16.200.60\t$LB_HOSTNAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"

    # firewall config to allow necessary worker node ports - allowing kube subnet
    # sudo ufw allow 22/tcp
    # sudo ufw allow 10250/tcp
    # sudo ufw allow 30000:32767/tcp
    sudo ufw allow from 172.16.200.0/24

    # Get and run script from master node to join cluster
    apt-get install -y sshpass
    sshpass -p "vagrant" scp -o StrictHostKeyChecking=no vagrant@$MASTER_NODE_IP:/etc/kubeadm_master_join_cmd.sh .
    sh ./kubeadm_master_join_cmd.sh
SCRIPT

$configureLoadBalancer = <<-SCRIPT
    echo "This is a load balancer node"
    # Add master nodes to /etc/hosts file
    ETC_HOSTS=/etc/hosts
    M1_HOSTS_LINE="172.16.200.55\tk8s-master01"
    M2_HOSTS_LINE="172.16.200.56\tk8s-master02"
    M3_HOSTS_LINE="172.16.200.57\tk8s-master03"
    sudo -- sh -c -e "echo '$M1_HOSTS_LINE' >> $ETC_HOSTS"
    sudo -- sh -c -e "echo '$M2_HOSTS_LINE' >> $ETC_HOSTS"
    sudo -- sh -c -e "echo '$M3_HOSTS_LINE' >> $ETC_HOSTS"

    # firewall config to allow necessary worker node ports - allowing kube subnet
    # sudo ufw allow 22/tcp
    # sudo ufw allow 10250/tcp
    # sudo ufw allow 30000:32767/tcp
    sudo ufw allow from 172.16.200.0/24

    # get haproxy
    # create config file
    mkdir haproxy
    cd ./haproxy/
    touch ./haproxy.cfg
    # https://www.ssltrust.com.au/help/setup-guides/haproxy-reverse-proxy-setup-guide
    cat > ./haproxy.cfg <<EOF
defaults
    mode tcp
    timeout connect 2000ms
    timeout client 10000ms
    timeout server 10000ms

frontend localhost
    # Only bind on 80 if you also want to listen for connections on 80
    bind *:80
    bind *:6443
    option tcplog
    default_backend nodes

backend nodes
    balance roundrobin
    option ssl-hello-chk
    # Add an entry for each of your backend servers and their resolvable hostnames
    server k8s-master01 172.16.200.55:6443 check
    server k8s-master02 172.16.200.56:6443 check
    server k8s-master03 172.16.200.57:6443 check
EOF

    # create dockerfile
    touch ./Dockerfile
    cat > ./Dockerfile <<EOF
# For docker image updates - https://hub.docker.com/_/haproxy
FROM haproxy:2.1.2
COPY haproxy.cfg /usr/local/etc/haproxy/haproxy.cfg
EOF

    # build docker image
    docker build -t my-haproxy .

    # run haproxy container
    docker run -d -p 6443:6443 -p 80:80 --name k8s-haproxy my-haproxy
SCRIPT

Vagrant.configure("2") do |config|

    servers.each do |opts|
        config.vm.define opts[:name] do |config|

            config.vm.box = opts[:box]
            config.vm.box_version = opts[:box_version]
            config.vm.hostname = opts[:name]
            config.vm.network :public_network, ip: opts[:eth1], bridge: "Intel(R) Dual Band Wireless-AC 8265" # bridged network
            #config.vm.network "private_network", type: "dhcp"

            config.vm.provider "virtualbox" do |v|

                v.name = opts[:name]
            	v.customize ["modifyvm", :id, "--groups", "/KubeDevelopment"]
                v.customize ["modifyvm", :id, "--memory", opts[:mem]]
                v.customize ["modifyvm", :id, "--cpus", opts[:cpu]]

            end

            # we cannot use this because we can't install the docker version we want - https://github.com/hashicorp/vagrant/issues/4871
            #config.vm.provision "docker"

            # set default route via bridged interface for the command below that's run on master node 
            # IP_ADDR=`ip route get 1 | awk '{print $NF;exit}'`
            config.vm.provision "shell",
            run: "always",
            inline: "sudo ip route add 0.0.0.0/0 via 172.16.200.1"

            config.vm.provision "shell", inline: $installDocker

            if opts[:type] == "loadbalancer"
                config.vm.provision "shell", inline: $configureLoadBalancer
            end
            if opts[:type] == "master"
                config.vm.provision "shell", inline: $installKubeComponents
                config.vm.provision "shell", inline: $configureMaster
            end
            if opts[:type] == "smaster"
                config.vm.provision "shell", inline: $installKubeComponents
                config.vm.provision "shell", inline: $configureSecondaryMasters
            end

        end

    end

end 