# -*- mode: ruby -*-
# vi: set ft=ruby :
#
# Change the following for your network setup:
#   MASTER_NODE_IP
#   eth1 IP addresses
#   bridged network config
#   Replace instances of 172.30.250.x to your local network

# Documentation for HA Master setup using Kubeadm
# https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/

servers = [
    {
        :name => "k8s-lb01",
        :type => "loadbalancer",
        :box => "ubuntu/bionic64",
        :box_version => "20201016.0.0",
        :eth1 => "172.30.250.60",
        :mem => "1024",
        :cpu => "1"
    },
    {
        :name => "k8s-master01",
        :type => "master",
        :box => "ubuntu/bionic64",
        :box_version => "20201016.0.0",
        :eth1 => "172.30.250.55",
        :mem => "2048",
        :cpu => "2"
    },
    {
        :name => "k8s-master02",
        :type => "smaster",
        :box => "ubuntu/bionic64",
        :box_version => "20201016.0.0",
        :eth1 => "172.30.250.56",
        :mem => "2048",
        :cpu => "2"
    },
    {
        :name => "k8s-master03",
        :type => "smaster",
        :box => "ubuntu/bionic64",
        :box_version => "20201016.0.0",
        :eth1 => "172.30.250.57",
        :mem => "2048",
        :cpu => "2"
    }
]

# This script will install Docker
$installDocker = <<-SCRIPT
    # kubelet requires swap off
    sudo swapoff -a

    # keep swap off after reboot
    sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

    # Letting iptables see bridged traffic
    cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
    net.bridge.bridge-nf-call-ip6tables = 1
    net.bridge.bridge-nf-call-iptables = 1
    EOF

    sudo sysctl --system

    # (Install Docker CE)
    ## docker versions and install instructions - https://kubernetes.io/docs/setup/production-environment/container-runtimes/#docker
    ## Set up the repository:
    ### Install packages to allow apt to use a repository over HTTPS
    apt-get update && apt-get install -y \
    apt-transport-https ca-certificates curl software-properties-common gnupg2

    # Add Docker's official GPG key:
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -

    # Add the Docker apt repository:
    add-apt-repository \
    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
    $(lsb_release -cs) \
    stable"

    # Install Docker CE
    apt-get update && apt-get install -y \
        containerd.io=1.2.13-2 \
        docker-ce=5:19.03.11~3-0~ubuntu-$(lsb_release -cs) \
        docker-ce-cli=5:19.03.11~3-0~ubuntu-$(lsb_release -cs)

    # Set up the Docker daemon
    cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF

    mkdir -p /etc/systemd/system/docker.service.d

    # Restart Docker
    systemctl daemon-reload
    systemctl restart docker

    # start docker service on boot
    sudo systemctl enable docker

    # add hostname to /etc/hosts file
    ETC_HOSTS=/etc/hosts
    IP_ADDR=`ip route get 1 | awk '{print $7;exit}'`
    HOST_NAME=$(hostname)
    HOSTS_LINE="$IP_ADDR\t$HOST_NAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"
SCRIPT

# This script to install k8s using kubeadm will get executed after a box is provisioned
$installKubeComponents = <<-SCRIPT
    # install kubeadm - https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
    curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
    cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
    deb https://apt.kubernetes.io/ kubernetes-xenial main
    EOF

    sudo apt-get update
    sudo apt-get install -y kubelet kubeadm kubectl

    # exclude Kube components from getting updated during normal maintenance
    sudo apt-mark hold kubelet kubeadm kubectl
SCRIPT

$configureMaster = <<-SCRIPT
    echo "This is a master node"
    # ip of this box
    IP_ADDR=`ip route get 1 | awk '{print $7;exit}'`
    POD_CIDR="192.168.0.0/16"

    # setup load balancer's hostname in hosts file
    ETC_HOSTS=/etc/hosts
    LB_HOSTNAME="k8s-lb01"
    HOSTS_LINE="172.30.250.60\t$LB_HOSTNAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"

    # firewall config to allow necessary master node ports - allowing kube subnet
    sudo ufw allow from 172.30.250.0/24

    # install k8s master with load balancer
    HOST_NAME=$(hostname)
    # generate cert key to pass to join script later
    CERT_KEY=$(kubeadm alpha certs certificate-key)
    sudo kubeadm init --control-plane-endpoint "$LB_HOSTNAME:6443" --upload-certs \
    --pod-network-cidr=$POD_CIDR --certificate-key $CERT_KEY

    # copying credentials to regular user - vagrant
    sudo mkdir -p $HOME/.kube
    sudo --user=vagrant mkdir -p /home/vagrant/.kube
    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    sudo cp -i /etc/kubernetes/admin.conf /home/vagrant/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config
    sudo chown $(id -u vagrant):$(id -g vagrant) /home/vagrant/.kube/config

    # Create join shell script for worker nodes with v=2 for more verbosity to help with troubleshooting
    kubeadm token create --print-join-command >> /etc/kubeadm_join_cmd.sh
    sudo sed -i '$ s/$/ --v=2/' /etc/kubeadm_join_cmd.sh
    chmod +x /etc/kubeadm_join_cmd.sh

    # Create join shell script for master nodes with v=2 for more verbosity to help with troubleshooting
    # https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/#cmd-token-create
    kubeadm token create --print-join-command --certificate-key $CERT_KEY >> /etc/kubeadm_master_join_cmd.sh
    sudo sed -i '$ s/$/ --v=2/' /etc/kubeadm_master_join_cmd.sh
    chmod +x /etc/kubeadm_master_join_cmd.sh

    # required for setting up password less ssh between guest VMs
    sudo sed -i "/^[^#]*PasswordAuthentication[[:space:]]no/c\PasswordAuthentication yes" /etc/ssh/sshd_config
    sudo service sshd restart

    # install Calico pod network addon
    # instructions: https://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises
    kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
SCRIPT

$configureSecondaryMasters = <<-SCRIPT
    echo "This is a secondary master node"
    # Add master node to /etc/hosts file
    ETC_HOSTS=/etc/hosts
    MASTER_NODE_IP="172.30.250.55"
    MASTER_HOST_NAME="k8s-master01"
    HOSTS_LINE="$MASTER_NODE_IP\t$MASTER_HOST_NAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"

    # setup load balancer's hostname in hosts file
    LB_HOSTNAME="k8s-lb01"
    HOSTS_LINE="172.30.250.60\t$LB_HOSTNAME"
    sudo -- sh -c -e "echo '$HOSTS_LINE' >> $ETC_HOSTS"

    # firewall config to allow necessary worker node ports - allowing kube subnet
    sudo ufw allow from 172.30.250.0/24

    # Get and run script from master node to join cluster
    apt-get install -y sshpass
    sshpass -p "vagrant" scp -o StrictHostKeyChecking=no vagrant@$MASTER_NODE_IP:/etc/kubeadm_master_join_cmd.sh .
    sh ./kubeadm_master_join_cmd.sh
SCRIPT

$configureLoadBalancer = <<-SCRIPT
    echo "This is a load balancer node"
    # Add master nodes to /etc/hosts file
    ETC_HOSTS=/etc/hosts
    M1_HOSTS_LINE="172.30.250.55\tk8s-master01"
    M2_HOSTS_LINE="172.30.250.56\tk8s-master02"
    M3_HOSTS_LINE="172.30.250.57\tk8s-master03"
    sudo -- sh -c -e "echo '$M1_HOSTS_LINE' >> $ETC_HOSTS"
    sudo -- sh -c -e "echo '$M2_HOSTS_LINE' >> $ETC_HOSTS"
    sudo -- sh -c -e "echo '$M3_HOSTS_LINE' >> $ETC_HOSTS"

    # firewall config to allow necessary worker node ports - allowing kube subnet
    sudo ufw allow from 172.30.250.0/24

    # get haproxy
    # create config file
    mkdir haproxy
    cd ./haproxy/
    touch ./haproxy.cfg
    # https://www.ssltrust.com.au/help/setup-guides/haproxy-reverse-proxy-setup-guide
    cat > ./haproxy.cfg <<EOF
defaults
    log global
    option tcplog
    mode tcp
    errorfile 503 /usr/local/etc/haproxy/errors/503.http
    errorfile 504 /usr/local/etc/haproxy/errors/504.http
    timeout connect 2000ms
    timeout client 10000ms
    timeout server 10000ms

frontend localhost
    # Only bind on 80 if you also want to listen for connections on 80
    bind *:80
    bind *:6443
    stats uri /proxystats
    default_backend k8sMasters

backend k8sMasters
    balance roundrobin
    option ssl-hello-chk
    # Add an entry for each of your backend servers and their resolvable hostnames
    server k8s-master01 172.30.250.55:6443 check
    server k8s-master02 172.30.250.56:6443 check
    server k8s-master03 172.30.250.57:6443 check

listen stats
    bind :9999
    mode http
    stats enable
    stats hide-version
    stats uri /stats
EOF

    # create dockerfile
    touch ./Dockerfile
    cat > ./Dockerfile <<EOF
# For docker image updates - https://hub.docker.com/_/haproxy
FROM haproxy:2.1.2
COPY haproxy.cfg /usr/local/etc/haproxy/haproxy.cfg
EOF

    # build docker image
    docker build -t k8s-haproxy .

    # run haproxy container
    docker run -d -p 6443:6443 -p 80:80 -p 9999:9999 --name k8s-haproxy k8s-haproxy
SCRIPT

Vagrant.configure("2") do |config|

    servers.each do |opts|
        config.vm.define opts[:name] do |config|

            config.vm.box = opts[:box]
            config.vm.box_version = opts[:box_version]
            config.vm.hostname = opts[:name]
            config.vm.network :public_network, ip: opts[:eth1], bridge: "Intel(R) Dual Band Wireless-AC 8265" # bridged network
            #config.vm.network "private_network", type: "dhcp"

            config.vm.provider "virtualbox" do |v|

                v.name = opts[:name]
            	v.customize ["modifyvm", :id, "--groups", "/KubeDevelopment"]
                v.customize ["modifyvm", :id, "--memory", opts[:mem]]
                v.customize ["modifyvm", :id, "--cpus", opts[:cpu]]

            end

            # we cannot use this because we can't install the docker version we want - https://github.com/hashicorp/vagrant/issues/4871
            #config.vm.provision "docker"

            # set default route via bridged interface for the command below that's run on master node 
            # IP_ADDR=`ip route get 1 | awk '{print $NF;exit}'`
            config.vm.provision "shell",
            run: "always",
            inline: "sudo ip route add 0.0.0.0/0 via 172.30.250.1"

            config.vm.provision "shell", inline: $installDocker

            if opts[:type] == "loadbalancer"
                config.vm.provision "shell", inline: $configureLoadBalancer
            end
            if opts[:type] == "master"
                config.vm.provision "shell", inline: $installKubeComponents
                config.vm.provision "shell", inline: $configureMaster
            end
            if opts[:type] == "smaster"
                config.vm.provision "shell", inline: $installKubeComponents
                config.vm.provision "shell", inline: $configureSecondaryMasters
            end

        end

    end

end 